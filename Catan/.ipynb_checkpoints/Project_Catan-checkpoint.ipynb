{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project (Option 1) - Settlers of Catan \n",
    "\n",
    "#### Authors:\n",
    "\n",
    "v1.0 (2016 Spring) David Marn, Ashvin Nair, Kabir Chandrasekher, Tony Duan, Kangwook Lee, Kannan Ramchandran\n",
    "\n",
    "v1.1 (2017 Spring) Tavor Baharav, Kabir Chandrasekhar, Sinho Chewi, Andrew Liu, Kamil Nar, David Wang, and Kannan Ramchandran\n",
    "\n",
    "v1.2 (2018 Spring) Tavor Baharav, Kaylee Burns, Gary Cheng, Sinho Chewi, Hemang Jangle, William Gan, Alvin Kao, Chen Meng, Vrettos Muolos, Kanaad Parvate, Ray Ramamurti, and Kannan Ramchandran\n",
    "\n",
    "v1.3 (2018 Fall) Justin Hong, Eric Liu, Ray Ramamurti, Raghav Anand, Kurtland Chua, Payam Delgosha, William Gan, Avishek Ghosh, Nikunj Jain, Katie Kang, Adarsh Karnati, Kanaad Parvate, Amay Saxena, Kannan Ramchandran, Abhay Parekh\n",
    "\n",
    "## Introduction\n",
    "The goal of the game is to get $10$ victory points as fast as possible. To get these points, the player must choose a wise trade-off between spending resources to potentially obtain points and upgrading their modes of production. You, the chieftain of the island, must decide where and when to build additional <font color=purple>settlements</font> on the island to boost your resource production, with roads to connect them. Alternatively, you can invest into development cards, which will bring you a victory point, or upgrade a settlement into a <font color=blue>city</font> which doubles production and gives you another victory point. A settlement / city must border on a resource field in order to harvest its resources. We will have three different terrains: forests, which produce <font color=brown>wood</font>, hills which produce <font color=red>brick</font>, and fields of <font color=gray>grain</font> (grain). Additionally we have <font color=khaki>desert</font> which provide no resources. Every turn, we roll two dice and record the sum $X$. The settlements that are next to the tile that is labelled with $X$ get one resource from that field, and we keep collecting resources and building up to 10 victory points.\n",
    "\n",
    "## Game layout\n",
    "\n",
    "Our modified Catan board is drawn below.\n",
    "\n",
    "Tiles are color coded with the resource they produce: <font color=brown>wood</font>, <font color=red>brick</font>, <font color=green>grain</font>. (and <font color=khaki>desert</font>)\n",
    "\n",
    "You build <font color=purple>settlements</font> and <font color=blue>cities</font> on vertices of the board. The small purple square is a settlement, labeled \"1\" because it gives you one resource of the surrounding tiles when the corresponding number is rolled. The small blue square is a city and gives you 2 resources from surrounding tiles.\n",
    "\n",
    "These settlements and cities must be connected by roads (white)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from catan import Catan, CatanException, get_random_dice_arrangement, Player, Game, simulate_1p_game, simulate_1p_game_with_data\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import repeat\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width, height = 4,4\n",
    "dice = get_random_dice_arrangement(width, height)\n",
    "resources = np.random.randint(0, 3, (height, width))\n",
    "board = Catan(dice, resources, {6:0, 16:1}, {13:0}, {(6, 7):0, (7, 12):0, (12, 13):0, (16,17): 1})\n",
    "board.register_player()\n",
    "board.register_player()\n",
    "board.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Rules\n",
    "When implementing your Catan strategy, remember to follow these rules:\n",
    "<ul>\n",
    "<li> Every turn you roll 2 dice, call the sum X </li>\n",
    "<li> Find tiles labeled with the number X and collect one of that resource for every settlement and two of that resource for every city on a vertex of that tile (this logic is implemented for you already) </li>\n",
    "<li> If a 7 is rolled, the player must dump resources until their total resource count is below the max resource limit. </li>\n",
    "<!---<li> You can never have more than 6 of any resource: if you get extra, you just keep 6 </li>--->\n",
    "<li> You can trade 4 resources of the same kind for a resource of your choice (i.e. 4 grain for 1 wood) </li>\n",
    "<li> If you have a settlement or a city built on one of the 4 ports (4 corners), you can trade at a discount <ul>\n",
    "<li> Bottom left hand corner: wood port, trade 2 wood for 1 of any other resource </li>\n",
    "<li> Bottom right hand corner: brick port, trade 2 brick for 1 of any other resource </li>\n",
    "<li> Upper left hand corner: grain port, trade 2 grain for 1 of any other resource </li>\n",
    "<li> Upper right hand corner: general port, trade 3 of any resource for 1 of any other resource </li>\n",
    "</ul></li>\n",
    "<li>Settlements must be connected by roads </li>\n",
    "<li>Roads must be connected to settlements / cities or other roads </li>\n",
    "<li>Settlements cannot be built adjacent to other settlements or cities </li>\n",
    "<li> You can build by paying resources according to the costs below, and building any non-road item (including buying a development card) gives you 1 victory point </li>\n",
    "<li> You start the game off with 3 of each resource and no buildings </li>\n",
    "<li> You may make as many purchases as you want per turn </li>\n",
    "<li> You are alloted 3 minutes of computation time per 100 games over a fixed board. </li>\n",
    "    <ul> <li> You are free to divide this time between planBoard and realtime computation as you wish\n",
    "        </li> </ul>\n",
    "</ul>\n",
    "\n",
    "## Costs\n",
    "You can build settlements or cities, which boost your production and gain you a victory point, buy roads to enable new settlement buying, or buy development cards which brings you an additional victory point.\n",
    "\n",
    "The costs are given below, and stored in the array costs for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wood</th>\n",
       "      <th>brick</th>\n",
       "      <th>grain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>settlement</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "costs = np.array([[2, 1, 1],\n",
    "                  [1, 2, 2],\n",
    "                  [0, 3, 3],\n",
    "                  [1, 1, 0]])\n",
    "\n",
    "resources = ['wood', 'brick', 'grain']\n",
    "buildings = ['settlement', 'card', 'city', 'road']\n",
    "df = pd.DataFrame(costs, index=buildings, columns=resources)\n",
    "html = df.to_html()\n",
    "from IPython.core.display import HTML\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Catan board is implemented for you, with utilities to draw and get a table of resources gained. Feel free to skip this for now, play with the demo below, then come back up to reread the details of the implementation.\n",
    "\n",
    " \n",
    "Here's a short API of the classes and methods implemented in catan.py (which you're encouraged to check out):\n",
    "\n",
    "#### BOARD CLASS\n",
    "\n",
    "To initialize a board: \n",
    "`board = Catan(dice, resources, settlements, cities)`\n",
    "\n",
    "The constructor initializes our Catan board. Dice and resources must be the same shape: HxW where H is the height of the board and W is the width. dice[i,j] is the dice number that tile corresponds to (each element between 2-12 inclusive) and resources[i,j] is the resource that tile  provides. Settlements is a dictionary mapping vertices with settlements on them to player ids, and likewise for cities.\n",
    "\n",
    "`board.clear_board()`\n",
    "clears the board for a new game.\n",
    "\n",
    "`board.register_player()`\n",
    "registers a player to play on this board.\n",
    "\n",
    "`board.build(x,y,building,player_id)`\n",
    "takes in two coordinates, x and y, a building type (\"city\"/\"settlement\"), and a player_id and builds that player's building at the specified location. If the building cannot be built at that location, an exception is thrown.\n",
    "\n",
    "`board.build_road(c0,c1,player_id)`\n",
    "takes in two vertex location tuples (x0,y0) and (x1,y1), and a player_id and builds a road between the two vertices. If the road cannot be built at that location, an exception is thrown.\n",
    "\n",
    "`board.if_can_build(building,x,y,player_id)`\n",
    "returns False if a building cannot be built at that vertex for that player. Otherwise, it returns True.\n",
    "\n",
    "`board.if_can_build_road(v1,v2,player_id)`\n",
    "returns False if a road cannot be built between vertices v1 and v2 for that player. Otherwise, it returns true.\n",
    "\n",
    "`board.is_port(vertex)`\n",
    "returns True if vertex is located on a port, False otherwise.\n",
    "\n",
    "`board.which_port(v)`\n",
    "returns which port vertex v corresponds to (0 : wood port, 1 : brick port, 2 : grain port, 3 : general port).\n",
    "\n",
    "`board.get_resources(player_id)`\n",
    "returns a 11x3 numpy array of resources gained for each possible dice sum for the given player. That is, r[i, :] = resources gained from throwing a (i+2).\n",
    "\n",
    "`board.draw()`\n",
    "draws the board.\n",
    "\n",
    "\n",
    "#### PLAYER CLASS\n",
    "\n",
    "`player = Player(player_name,action,dumpPolicy,resources,points=0,turn_counter=0)`\n",
    "Where player_name is a string, an action is a function, dumpPolicy is a function, resources is an array, points and turn_counter are integers used for debugging.\n",
    "\n",
    "`player.join_board(board)`\n",
    "takes in a board instance and registers the player to this board, and reinitializes the player instance variables to the default initialization.\n",
    "\n",
    "`player.get_settlements()`\n",
    "`player.get_cities()`\n",
    "`player.get_roads)`\n",
    "gets a list of the players respective pieces from the board the player is registered with.\n",
    "\n",
    "`player.if_can_buy(item)` \n",
    "returns True if the player can afford item (\"card\"/\"settlement\"/\"city\") and False otherwise\n",
    "\n",
    "`player.buy(item)` \n",
    "actually buys the item and throws a CatanException if that is not possible. Note that you need to specify the location of an item with the optional arguments `x`,`y` if you are buying a city, settlement, or road.\n",
    "\n",
    "`player.trade(r_in,r_out)`\n",
    "Trades resource r_in for r_out with ratio 4:1, unless player owns a port allowing for better trades. Throws an exception if player does not have the required amount of resource r_in to complete the trade.\n",
    "\n",
    "\n",
    "#### TESTING\n",
    "\n",
    "To initialize a game:\n",
    "`game = Game(board, players)` where board is a `Catan` instance and players are a list of `Player` instances.\n",
    "\n",
    "`game.play_round()` \n",
    "plays one round of Catan: rolls the dice, collects the resources and calls the function action() for each player once.\n",
    "\n",
    "`game.check_win()`\n",
    "checks if a player has one and if so, returns the player's name and the number of turns played. If not, returns false.\n",
    "\n",
    "`game.run_game_to_completion()`\n",
    "runs a single game and returns the winner's name and the number of turns the winner took to win.\n",
    "\n",
    "`game.restart_game()`\n",
    "restarts the players and the game board for a new game.\n",
    "\n",
    "`game.simulate_game(num_trials)`\n",
    "simulates $num\\_trials$ games and returns a dictionary mapping player names to their $[average\\_turns, win\\_rate]$.\n",
    "\n",
    "`game.simulate_one_game_with_data()`\n",
    "simulates one game and returns a list of settlements, cities, roads, hands, live_points, and dice_rolls at each turn.\n",
    "\n",
    "`simulate_1p_game(action, dumpPolicy, planBoard, board, num_trials)`\n",
    "Simulates $num\\_trials$ games on $board$, with the precompute method $planBoard$ to be used beforehand, and the $action$ and $dumpPolicy$ methods for a one player game. Returns the average turns taken to win.\n",
    "\n",
    "`simulate_1p_game_with_data(action, dumpPolicy, planBoard, board)`\n",
    "simulates a one player game with the respective methods and board, returning a list of settlements, cities, roads, hands, live_points, and dice_rolls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=blue>$\\mathcal{Q}$1. Learning the Game</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing...\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7ZYuSrfpjGcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "board.draw()\n",
    "print(board.get_resources())\n",
    "\n",
    "# wood is brown, brick is red, grain is green \n",
    "# below is the resource outcome of a dice roll 2-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Simulation\n",
    "\n",
    "Run the code below to see a game in action! This will use our (bad) sample policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average turns to win: 263\n"
     ]
    }
   ],
   "source": [
    "# sample action function: takes in the \"Player\"\n",
    "def action(self):\n",
    "    # inputs:\n",
    "    # resources - an array of resources\n",
    "    # costs - an array of costs, 0 - settlement, 1 - card, 2 - city\n",
    "    # basic strategy: Once we get 4 of one resource, we make a trade. \n",
    "    # Then we try to buy development cards\n",
    "    if self.get_settlements() == []:\n",
    "        (x,y) = self.preComp #use the optimal settlement location  \n",
    "        self.buy(\"settlement\", x, y) # we determined previously\n",
    "    elif self.if_can_buy(\"card\"):\n",
    "        self.buy(\"card\")\n",
    "    elif self.resources[np.argmax(self.resources)] >= 4:\n",
    "        rmax, rmin = np.argmax(self.resources), np.argmin(self.resources)\n",
    "        self.trade(rmax,rmin)\n",
    "    return\n",
    "\n",
    "# sample dump policy function: takes in the \"Player\" and ROBBER_MAX_RESOURCES\n",
    "# and returns a resource array which indicates the number of each resource to dump.\n",
    "# self.resources - dumpPolicy(self, max_resources) must sum up to less than or equal ROBBER_MAX_RESOURCES\n",
    "def dumpPolicy(self, max_resources):\n",
    "    new_resources = np.minimum(self.resources, max_resources // 3)\n",
    "    return self.resources - new_resources\n",
    "\n",
    "def planBoard(baseBoard):\n",
    "    # prefer middle of the board over edges\n",
    "    x = np.random.randint(1, baseBoard.width)\n",
    "    y = np.random.randint(1, baseBoard.height)\n",
    "    optSettlementLoc = (x,y)\n",
    "    return optSettlementLoc\n",
    "    \n",
    "num_trials = 100\n",
    "\n",
    "width, height = 4, 4\n",
    "dice = get_random_dice_arrangement(width, height)\n",
    "resources = np.random.randint(0, 3, (height, width))\n",
    "board = Catan(dice, resources)\n",
    "print(\"average turns to win: {}\".format(simulate_1p_game(action, dumpPolicy, planBoard, board, num_trials)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settlements, cities, roads, hands, live_points, dice_rolls = simulate_1p_game_with_data(action, dumpPolicy, planBoard, board)\n",
    "\n",
    "def draw(t):\n",
    "    t = int(t)\n",
    "    live_board = Catan(board.dice, board.resources, [], [])\n",
    "    live_board.settlements = settlements[t]\n",
    "    live_board.cities = cities[t]\n",
    "    live_board.roads = roads[t]\n",
    "    print(\"turn:\", t)\n",
    "    print(\"points:\", live_points[t])\n",
    "    print(\"dice roll:\", dice_rolls[t])\n",
    "    print(\"resources:\", hands[t])\n",
    "    live_board.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6372ebcabe4347bebc7cacfe594beb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.draw>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If this cell doesn't work, run the two commands below in terminal\n",
    "# pip install ipywidgets\n",
    "# jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "\n",
    "from ipywidgets import *\n",
    "interact(draw, t=(0, len(live_points) - 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are responsible for designing a good action / planning policy. Keep in mind that you are only allowed to modify these two methods, and that your action / planBoard functions must operate within a time constraint (under 3 minutes for 100 trials on a fixed board)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition\n",
    "As you may have noticed, the Board, Player, and Game classes are also designed for multiplayer games. We would like you to design player functions optimized against $n$ other players on the game board. Do your best to outcompete our staff `Player` class which will be released later on. An example of how to play games against different players is provided below. In our example, we play our (bad) sample policy against itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 2 has a win rate of 0.51, with average 321.0 turns per won game\n",
      "Player 1 has a win rate of 0.49, with average 299.0 turns per won game\n"
     ]
    }
   ],
   "source": [
    "# Initialize board\n",
    "dice = get_random_dice_arrangement(width, height)\n",
    "resources = np.random.randint(0, 3, (height, width))\n",
    "board = Catan(dice, resources)\n",
    "\n",
    "# Initialize players\n",
    "player1 = Player(\"Player 1\", action, dumpPolicy, planBoard)\n",
    "player2 = Player(\"Player 2\", action, dumpPolicy, planBoard)\n",
    "\n",
    "# Initialize game\n",
    "game = Game(board, [player1, player2])\n",
    "\n",
    "# Simulate game and report results\n",
    "results = game.simulate_game(num_trials)\n",
    "for r in results:\n",
    "    print(\"{} has a win rate of {}, with average {} turns per won game\".format(r, results[r][1], round(results[r][0], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=blue> Efficient Optimization [OPTIONAL]\n",
    "### <font color=blue> This is just one suggestion of how to proceed. The important thing is to separate the adversarial real world game of Catan from this simulation, and to think in a stochastic optimization mindset. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final phase of the project, use the tools you wrote above to figure out the best action sequence to minimize the time until you reach 10 points. To make our calculations tractable we can compute something a little different than finding the optimum action over all actions and all possible game states. Instead, we can reduce the goal at any given moment to building the _next_ objective. In this framework, we need to minimize the expected time from having no resources to building each objective. The below questions are optional but we recommend at least looking over them to see the topics we cover in class from a computing point of view, and it can be part of your \"extension\" to the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a few more utility functions you may use to handle converting state triplets into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hand = (w, b, g)\n",
    "LIMIT = 7 # can have 0-6 of each resource\n",
    "\n",
    "def encode(w, b, g):\n",
    "    return LIMIT * LIMIT * w + LIMIT * b + g\n",
    "\n",
    "def decode(n):\n",
    "    x = n % (LIMIT * LIMIT)\n",
    "    return (n // (LIMIT * LIMIT), x // LIMIT, x % LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = np.array((LIMIT-1, LIMIT-1, LIMIT-1))\n",
    "def floor(state):\n",
    "    return np.minimum(l, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <font color=blue> 1. Create a function `get_transition_matrix` which returns the transition matrix of your Markov chain. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transition_matrix(board):\n",
    "    \"\"\"returns matrix T[i, j] = P(transition from state i to state j)\"\"\"\n",
    "    ### Fill in your solution here\n",
    "    return np.zeros((2,2))\n",
    "\n",
    "T = transition_matrix(board)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=blue> Calculating Hitting Time</font>\n",
    "\n",
    "Let's start by building a useful function to answer the question: given a board layout and starting resources, how long will it take until you can afford a specific building?\n",
    "\n",
    "Hint: one method would be to create another Markov chain/transition matrix where the hitting time between two of the states gives the time until you can afford a building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> 2a. Write a function to calculate mean hitting time from 0 resources until you can afford a building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hitting_time(board, building):\n",
    "    ### your code here\n",
    "    return [42]\n",
    "    \n",
    "h = hitting_time(board, 1) # calculates time until we can afford a VP card\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue> 2b. Simulate the Markov process and record the expected hitting time to states to check the accuracy of your hitting time function. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simulator goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can minimize total expected hitting time with your policy using your hitting time function to speed up the optimization instead of simulating everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  8  3  7]\n",
      " [ 3  8  2  9]\n",
      " [10  4 11  6]\n",
      " [12 11 12  4]]\n",
      "[[ 2  2  2 -1]\n",
      " [ 2  2  1  2]\n",
      " [ 0  1  0  1]\n",
      " [ 0  2  2  2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(board.dice)\n",
    "print(board.resources)\n",
    "board.resources[3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_map(x):\n",
    "    \n",
    "    probs = {\n",
    "        0 : 0,\n",
    "        2 : 1.0/36,\n",
    "        3 : 2.0/36,\n",
    "        4 : 3.0/36,\n",
    "        5 : 4.0/36,\n",
    "        6 : 5.0/36,\n",
    "        7 : 6.0/36,\n",
    "        8 : 5.0/36,\n",
    "        9 : 4.0/36,\n",
    "        10 : 3.0/36,\n",
    "        11 : 2.0/36,\n",
    "        12 : 1.0/36\n",
    "    }\n",
    "    return probs[x]\n",
    "\n",
    "def average_city_returns(board_dice):\n",
    "    \"\"\"Take in dice object and calculates the expected returns of a building over all settlement locations\"\"\"\n",
    "\n",
    "    \n",
    "    values = board_dice\n",
    "    prob_map_v = np.vectorize(prob_map)\n",
    "    values = prob_map_v(values)\n",
    "    values = np.pad(values, [(1, 1), (1, 1)], mode='constant')\n",
    "    vecs = np.zeros(((values.shape[0]-1)*(values.shape[1]-1), 4))\n",
    "    for i in range(values.shape[0]-1):\n",
    "        for j in range(values.shape[1]-1):\n",
    "            vecs[i*(values.shape[1]-1)+ j] = values[i:i+2, j:j+2].reshape(1, 4)\n",
    "    sum_vec = np.ones(4)\n",
    "    vecs = np.dot(vecs, sum_vec)\n",
    "    return np.sum(vecs)/vecs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priority_weight(score):\n",
    "    priority_resources = {\n",
    "        0:(0.5,0.3,0.2), \n",
    "        1:(0.4,0.3,0.3), \n",
    "        2:(0.4,0.3,0.3), \n",
    "        3:(0.3,0.35,0.35), \n",
    "        4:(0.3,0.3,0.4), \n",
    "        5:(0.2,0.3,0.5), \n",
    "        6:(0.1,0.2,0.7), \n",
    "        7:(0.1,0.3,0.6),\n",
    "        8:(0.1,0.4,0.5), \n",
    "        9:(0.2,0.4,0.4)\n",
    "    }\n",
    "    return priority_resources[score]\n",
    "# for i in range(10):\n",
    "#     print(get_priority_weight(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_port(self, x, y):\n",
    "    port_const = 1.5\n",
    "    val = 0\n",
    "    if(x == 0):\n",
    "        val = prob_map(self.board.dice[0, 0]) if y == 0 else prob_map(self.board.dice[x, y-1])\n",
    "    if(x == self.board.height):\n",
    "        val = prob_map(self.board.dice[x-1, 0]) if y == 0 else prob_map(self.board.dice[x-1, y-1])\n",
    "\n",
    "    return val * port_const * self.average_city_return(self.board.dice)\n",
    "\n",
    "def handle_edge(self, x, y):\n",
    "    loc_val = np.array([0, 0, 0])\n",
    "    if(x == 0):\n",
    "        if(self.board.resources[x, y] != -1):\n",
    "            loc_val[self.board.resources[x, y]] += prob_map(solf.board.dice[x, y])\n",
    "        if(self.board.resources[x, y-1] != -1):\n",
    "            loc_val[self.board.resources[x, y-1]] += prob_map(solf.board.dice[x, y-1])\n",
    "    elif(x == self.board.height):\n",
    "        if(self.board.resources[x-1, y] != -1):\n",
    "            loc_val[self.board.resources[x-1, y]] += prob_map(solf.board.dice[x-1, y])\n",
    "        if(self.board.resources[x-1, y-1] != -1):\n",
    "            loc_val[self.board.resources[x-1, y-1]] += prob_map(solf.board.dice[x-1, y-1])\n",
    "    elif(y == self.board.width):\n",
    "        if(self.board.resources[x, y-1] != -1):\n",
    "            loc_val[self.board.resources[x, y-1]] += prob_map(solf.board.dice[x, y-1])\n",
    "        if(self.board.resources[x-1, y-1] != -1):\n",
    "            loc_val[self.board.resources[x-1, y-1]] += prob_map(solf.board.dice[x-1, y-1])\n",
    "    else:\n",
    "        if(self.board.resources[x, y] != -1):\n",
    "            loc_val[self.board.resources[x, y]] += prob_map(solf.board.dice[x, y])\n",
    "        if(self.board.resources[x-1, y] != -1):\n",
    "            loc_val[self.board.resources[x-1, y]] += prob_map(solf.board.dice[x-1, y])\n",
    "    return loc_val\n",
    "\n",
    "def best_loc(self, locations):\n",
    "    expected = dict()\n",
    "    score_dist = priority_resources[self.points]\n",
    "    for loc in locations:\n",
    "        loc_val = np.array([0, 0, 0])\n",
    "        x = loc[0]\n",
    "        y = loc[1]\n",
    "        if self.board.is_port(loc):\n",
    "            expected[loc] = handle_port(x, y)\n",
    "        elif (x == 0 or y == 0 or x == self.board.height or y == self.board.height):\n",
    "            expected[loc] = np.dot(handle_edge(x, y), score_dist)\n",
    "        else:\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    if(self.board.resources[x-i, y-j] != -1):\n",
    "                        loc_val[self.board.resources[x-i, y-j]] += prob_map(solf.board.dice[x-i, y-j]) \n",
    "            expected[loc] = np.dot(loc_val, score_dist)\n",
    "    return max(expected, key=expected.get)\n",
    "                    \n",
    "def next_settlement(self):        \n",
    "    locations = set()\n",
    "    potential_places = self.get_roads()\n",
    "    if len(potential_places) > 0:\n",
    "        for road in potential_places:\n",
    "            if self.board.if_can_build(\"settlement\", road[0][0], road[0][1], self.player_id):\n",
    "                locations.add(road[0])\n",
    "            if self.board.if_can_build(\"settlement\", road[1][0], road[1][1], self.player_id):\n",
    "                locations.add(road[1])\n",
    "    else:\n",
    "        for i in range(self.board.height+1):\n",
    "            for j in range(self.board.width+1):\n",
    "                if self.if_can_build(\"settlement\", i, j, self.player_id):\n",
    "                    locations.add((i, j))\n",
    "    return best_loc(locations)\n",
    "\n",
    "def next_city(self):\n",
    "    for i in range(self.board.height+1):\n",
    "        for j in range(self.board.width+1):\n",
    "            if self.if_can_build(\"city\", i, j, self.player_id):\n",
    "                locations.add((i, j))\n",
    "    return best_loc(locations)\n",
    "                    \n",
    "def next_road(self):\n",
    "    score_dist = priority_resources[self.points]\n",
    "    expectation = dict()\n",
    "    locations = []\n",
    "    for i in range(self.board.height):\n",
    "        for j in range(self.board.width):\n",
    "            if self.board.if_can_build_road((i, j), (i+1, j), self.player_id):\n",
    "                locations.append(((i, j), (i+1, j)))\n",
    "            if self.board.if_can_build_road((i, j), (i, j+1), self.player_id):\n",
    "                locations.append(((i, j), (i, j+1)))\n",
    "        if self.board.if_can_build_road((i, self.board.width), (i+1, self.board.width), self.player_id):\n",
    "                locations.append(((i, self.board.width), (i+1, self.board.width)))\n",
    "    for j in range(self.board.width):\n",
    "        if self.board.if_can_build_road((self.board.height, j), (self.board.height, j+1), self.player_id):\n",
    "            locations.append(((self.board.height, j), (self.board.height, j+1)))\n",
    "    \n",
    "    for loc in locations:\n",
    "        vec = np.array([0, 0, 0])\n",
    "        s = loc[0]\n",
    "        e = loc[1]\n",
    "        if(s[0] == 0 and e[0] == 0) or (s[1] == 0 and e[1] == 0):\n",
    "            vec[self.board.resources[s[0], s[1]]] += prob_map(self.dice[s[0], s[1]])\n",
    "        elif(s[0] == self.board.height and e[0] == self.board.height):\n",
    "            vec[self.board.resources[self.board.height-1, s[1]]] += prob_map(self.dice[self.board.height-1, s[1]])\n",
    "        elif(s[1] == self.board.width and e[1] == self.board.width):\n",
    "            vec[self.board.resources[s[0], self.board.width-1]] += prob_map(s[0], self.dice[self.board.width-1])\n",
    "        elif(s[0] == e[0]):\n",
    "            vec[self.board.resources[s[0], s[1]]] += prob_map(self.dice[s[0], s[1]])\n",
    "            vec[self.board.resources[s[0]-1, s[1]]] += prob_map(self.dice[s[0]-1, s[1]])\n",
    "        else:\n",
    "            vec[self.board.resources[s[0], s[1]]] += prob_map(self.dice[s[0], s[1]])\n",
    "            vec[self.board.resources[s[0], s[1]-1]] += probs_map(self.dice[s[0], s[1]-1])\n",
    "        expectation[loc] = np.dot(vec, score_dist)\n",
    "    return max(expected, key=expected.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a2627dfb8f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;31m# print(seq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0mbestseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomputeAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnSteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbestseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0mseq_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-a2627dfb8f77>\u001b[0m in \u001b[0;36mcomputeAction\u001b[0;34m(nSteps, min_diff, min_diff_steps, max_simulation_Dice, stepsPerConsensus)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mcurr_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcurr_steps\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mnSteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mbestseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstepsPerConsensus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mnextstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbestseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-a2627dfb8f77>\u001b[0m in \u001b[0;36mmcmc\u001b[0;34m(resource)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbestseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetActionSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnSteps\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcurr_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mseq_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "simulating=False\n",
    "seq_copy=[]\n",
    "seq=[]\n",
    "\n",
    "def dumpPolicy(self, max_resources):\n",
    "    new_resources = np.minimum(self.resources, max_resources // 3)\n",
    "    return self.resources - new_resources\n",
    "\n",
    "nSteps=60\n",
    "actions = ['settlement','city','road','card','trade_wood','trade_brick','trade_grain','rollDices']\n",
    "def computeAction(nSteps,min_diff=3,min_diff_steps=3,max_simulation_Dice=200,stepsPerConsensus=10):\n",
    "    global seq,seq_copy\n",
    "    simulating=True    \n",
    "    def mcmc(resource):\n",
    "        global seq,seq_copy\n",
    "        bestseq=getActionSeq(nSteps-curr_steps)\n",
    "        seq=result[:idx].copy()\n",
    "        seq.extend(bestseq)\n",
    "        seq_copy=[]\n",
    "        best_turns= simulate_1p_game(action, dumpPolicy, planBoard, board, 1)           \n",
    "        \n",
    "        nruns=0\n",
    "        stableSteps=0\n",
    "        stable=False\n",
    "        \n",
    "        while nruns<max_simulation_Dice:\n",
    "            currentseq=getActionSeq(nSteps-curr_steps)\n",
    "            seq=result[:idx].copy()\n",
    "            seq.extend(currentseq)\n",
    "            seq_copy=[]\n",
    "            curr_turns=simulate_1p_game(action, dumpPolicy, planBoard, board, 1)\n",
    "            if np.absolute(best_turns-curr_turns)<=min_diff:\n",
    "                stableSteps+=1\n",
    "                stable=True\n",
    "            else:\n",
    "                stableSteps=0\n",
    "                stable=False\n",
    "            if curr_turns>best_turns or np.random.random<np.exp(curr_turns-best_turns):\n",
    "                best_turns=curr_turns\n",
    "                bestseq=currentseq\n",
    "                nruns+=1\n",
    "            if stableSteps==min_diff_steps:\n",
    "                return bestseq\n",
    "        return bestseq\n",
    "\n",
    "    result=[None]*400\n",
    "    idx=0\n",
    "    curr_steps=0\n",
    "    while curr_steps<nSteps:\n",
    "        bestseq=mcmc(resources)\n",
    "        for s in range(stepsPerConsensus):\n",
    "            nextstep=bestseq.pop(0)\n",
    "            if idx==len(result):\n",
    "                result.extend([None]*400)\n",
    "            result[idx]=nextstep\n",
    "            idx+=1\n",
    "            if nextstep=='rollDices':\n",
    "                curr_steps+=1\n",
    "    simulating=False\n",
    "    return result        \n",
    "    \n",
    "def getActionSeq(nSteps):\n",
    "    seq=[None]*400\n",
    "    roll=0\n",
    "    idx=0\n",
    "    while roll<nSteps:\n",
    "        nextaction=actions[np.random.randint(0,len(actions))]\n",
    "        if idx==len(seq):\n",
    "            seq.extend([None]*400)\n",
    "        seq[idx]=nextaction\n",
    "        idx+=1\n",
    "        if nextaction=='rollDices':\n",
    "            roll+=1\n",
    "    return seq    \n",
    "    \n",
    "def action(self):\n",
    "    global seq,seq_copy\n",
    "    if np.array_equal(self.resources,self.init_resources) and self.points==self.init_points and len(self.get_settlements())==0 and len(self.get_cities())==0 and len(self.get_roads())==0:\n",
    "        if len(seq_copy)>0:\n",
    "            seq=seq_copy.copy()\n",
    "        else:\n",
    "            seq_copy=seq.copy()  \n",
    "    a=seq.pop(0)\n",
    "    actions_copy=actions.copy()\n",
    "    actions_copy.remove(a)\n",
    "    while ((a in actions[0:4]) and not self.if_can_buy(a)) or ((a in actions[4:7] and not if_can_trade(self,a))):\n",
    "        a=np.random.choice(actions_copy)\n",
    "        actions_copy.remove(a)            \n",
    "\n",
    "    if a== 'settlement':\n",
    "        (x,y)=optimal_settlement()\n",
    "        self.buy('settlement',x,y)\n",
    "        print('insert optimal function')\n",
    "    elif a=='city':\n",
    "        (x,y)=optimal_city()\n",
    "        self.buy('city',x,y)\n",
    "    elif a=='road':\n",
    "        (x,y)=optimal_road()\n",
    "        self.buy('road',x,y)\n",
    "    elif a=='card':\n",
    "        self.buy('card')\n",
    "    elif a=='trade_wood':\n",
    "        rin = optimal_trade('wood')\n",
    "        self.trade(rin,'wood')\n",
    "    elif a=='trade_brick':\n",
    "        rin = optimal_trade('brick')\n",
    "        self.trade(rin,'brick')\n",
    "    elif a=='grain':\n",
    "        rin = optimal_trade('grain')\n",
    "        self.trade(rin,'grain')\n",
    "    \n",
    "\n",
    "def if_can_trade(self,rout):\n",
    "    if self.resources[np.argmax(self.resources)] >= 4:\n",
    "        return True\n",
    "    else:\n",
    "        for s in self.get_settlements():\n",
    "            if self.board.is_port(s) and self.resources[self.board.which_port(s)]>=2:\n",
    "                return True\n",
    "        for s in self.get_cities():\n",
    "            if self.board.is_port(s) and self.resources[self.board.which_port(s)]>=2:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def planBoard(baseBoard):\n",
    "    # prefer middle of the board over edges\n",
    "    x = np.random.randint(1, baseBoard.width)\n",
    "    y = np.random.randint(1, baseBoard.height)\n",
    "    optSettlementLoc = (x,y)\n",
    "    return optSettlementLoc\n",
    "\n",
    "num_trials = 100\n",
    "\n",
    "width, height = 4, 4\n",
    "dice = get_random_dice_arrangement(width, height)\n",
    "resources = np.random.randint(0, 3, (height, width))\n",
    "board = Catan(dice, resources)\n",
    "\n",
    "import time\n",
    "start=time.time()\n",
    "\n",
    "# print(seq)\n",
    "bestseq=computeAction(nSteps)\n",
    "seq=bestseq\n",
    "seq_copy=[]\n",
    "print(\"average turns to win: {}\".format(simulate_1p_game(action, dumpPolicy, planBoard, board, num_trials)))\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dice_test = get_random_dice_arrangement(width, height)\n",
    "resources_test = np.random.randint(0, 3, (height, width))\n",
    "board = Catan(dice, resources)\n",
    "board.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
